---
title: The RGCCA package for Regularized/Sparse Generalized Canonical Correlation
  Analysis
date: "`r Sys.Date()`"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    toc: yes
    df_print: paged
vignette: |
  %\VignetteIndexEntry{The RGCCA package for Regularized/Sparse Generalized Canonical Correlation Analysis} %\VignetteEngine{knitr::rmarkdown} \usepackage[utf8]{inputenc}
header-includes:
- \usepackage{amsfonts}
- \usepackage{algorithm2e}
- \usepackage{times}
- \usepackage{bm}
- \usepackage{soul}
- \usepackage{epsfig}
- \usepackage{amssymb}
- \usepackage{natbib}
- \usepackage{lscape}
- \usepackage{graphicx}
- \usepackage{tikz}
- \usetikzlibrary{arrows}
- \usepackage{amsmath}
- \usepackage{color}
- \usepackage{float}
- \usepackage{amsfonts}
- \usepackage{latexsym}
- \usepackage{graphicx,psfrag,color}
- \usepackage{amsmath,amssymb}
- \usepackage{multirow}
- \usepackage{amsthm}
- \usepackage{enumerate}
- \usepackage{enumitem}
- \usepackage{setspace}
- \usepackage{subfigure}
- \usepackage{longtable}
- \usepackage{etoolbox}
- \usepackage{pdfpages}
- \usepackage[mathscr]{euscript}
- \usepackage[T1]{fontenc}
- \usepackage[english]{babel}
- \usepackage[misc]{ifsym}
- \usepackage{wasysym}
- \usepackage{hyperref}
- \usepackage{breakurl}
- \usepackage{pgfplots}
- \usepackage{microtype}
bibliography: biblio.bib
---

```{=tex}
\newcommand{\ma}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\sign}{\ensuremath{\mathrm{sign}}}
\newcommand{\cov}{\ensuremath{\text{cov}}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\A}{\mathbf{A}}
\newcommand{\Q}{\mathbf{Q}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\mbc}{\mathbf{c}}
\newcommand{\I}{\mathbf{I}}
\newcommand{\mbP}{\mathbf{P}}
\newcommand{\mba}{\mathbf{a}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\mbb}{\mathbf{b}}
\newcommand{\Xu}{\underline{\mathbf{X}}}
\newcommand{\Pu}{\underline{\mathbf{P}}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\K}{\mathbf{K}}
\newcommand{\mcH}{\mathcal{H}}
\newcommand{\bsx}{\boldsymbol{x}}
\newcommand{\bsxi}{\boldsymbol{\xi}}
\newcommand{\bsa}{\boldsymbol{\alpha}}
\newcommand{\mat}[1]{\textbf{\text{#1}}}
```
```{=tex}
\bibliographystyle{apalike}
\bibliography{biblio}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 4)
```

```{r}
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
```

# Introduction

A challenging problem in multivariate statistics is to study relationships between several sets of variables measured on the same set of individuals. In the literature, this paradigm can be stated under several names as "learning from multimodal data", "data integration", "data fusion" or "multiblock data analysis". Typical examples are found in large variety of fields such as biology, chemistry, sensory analysis, marketing, food research, where the common general objective is to identify variables of each block that are active in the relationships with other blocks. For instance, neuroimaging is increasingly recognised as an intermediate phenotype to understand the complex path between genetics and behavioural or clinical phenotypes. In this imaging-genetics context, the goal is primarily to identify a set of genetic biomarker that explains some neuroimaging variability which implies some modification of the behavioural. A second application is found in molecular biology where the completion of the human genome sequence has shifted research efforts in genomics toward understanding the effect of sequence variation on gene expression, protein function, or other cellular mechanims. Both in the imaging-genetics and the multi-modal genetic context, it is crucial to perform multiple experiments (e.g. SNPs, functional MRI, behavioural data) on a single set of patients and the joint analysis of multiple datasets becomes more and more crucial. The RGCCA package aims to propose a unified and flexible framework for that purpose.

# Multiblock data analysis with the RGCCA package

For the sake of comprehension of the use of the RGCCA package, the theoretical foundations of RGCCA and variations - that were previously published [@Tenenhaus2011 ; @Tenenhaus2014 ; @Tenenhaus2015 ; @Tenenhaus2017] - are briefly summarized.

We consider $J$ data matrices $\mathbf{X}_1, \ldots, \mathbf{X}_J$. Each $n \times p_j$ data matrix $\mathbf{X}_j = [\ensuremath{\mathbf{x}}_{j1}, \ldots, \ensuremath{\mathbf{x}}_{jp_j}]$ is called a block and represents a set of $p_j$ variables observed on $n$ individuals. The number and the nature of the variables may differ from one block to another, but the individuals must be the same across blocks. We assume that all variables are centered. The objective of RGCCA is to find, for each block, a weighted composite of variables (called block component) $\mathbf{y}_j= \mathbf{X}_j \ensuremath{\mathbf{a}}_j,j=1, \ldots,J$ (where $\ensuremath{\mathbf{a}}_j$ is a column-vector with $p_j$ elements) summarizing the relevant information between and within the blocks. The block components are obtained such that (i) block components explain well their own block and/or (ii) block components that are assumed to be connected are highly correlated. In addition, RGCCA integrates a variable selection procedure, called SGCCA, allowing the identification of the most relevant features. Finally, as a component-based method, RGCCA/SGCCA can provide users with graphical representations to visualize the sources of variability within blocks and the amount of correlation between blocks.

## Regularized Generalized Canonical Correlation Analysis

The most recent formulation of RGCCA [@Tenenhaus2017] subsumes fifty years of multiblock component methods. It provides improvements to the initial version of RGCCA [@Tenenhaus2011] and is defined as the following optimization problem:

```{=tex}
\begin{equation}
\displaystyle \underset{\ensuremath{\mathbf{a}}_1,\ensuremath{\mathbf{a}}_2, \ldots,\ensuremath{\mathbf{a}}_J}{\text{maximize}} \sum_{j, k = 1}^J c_{jk}g(\mathrm{cov}(\mathbf{X}_j\ensuremath{\mathbf{a}}_j, \mathbf{X}_k\ensuremath{\mathbf{a}}_k)) \mathrm{~~s.t.~~} (1-\tau_j)\mathrm{var}(\mathbf{X}_j\ensuremath{\mathbf{a}}_j) + \tau_j\Vert \ensuremath{\mathbf{a}}_j \Vert^2 = 1, j=1, \ldots,J
\label{optim_RGCCA}
\end{equation}
```
where:

-   The scheme function $g$ is any continuously differentiable convex function. Typical choices of $g$ are the identity (horst scheme, leading to maximizing the sum of covariances between block components), the absolute value (centroid scheme, yielding maximization of the sum of the absolute values of the covariances), the square function (factorial scheme, thereby maximizing the sum of squared covariances), or, more generally, for any even integer $m$, $g(x) = x^m$ (m-scheme, maximizing the power of $m$ of the sum of covariances). The horst scheme penalizes structural negative correlation between block components while both the centroid scheme and the m-scheme enable two components to be negatively correlated. According to [@VandeGeer1984], a fair model is a model where all blocks contribute equally to the solution in opposition to a model dominated by only a few of the $J$ sets. If fairness is a major objective, the user must choose $m=1$. $m>1$ is preferable if the user wants to discriminate between blocks. In practice, $m$ is equal to $1$, $2$ or $4$. The higher the value of $m$ the more the method acts as block selector [@Tenenhaus2017].

-   The design matrix $\ensuremath{\mathbf{C}}$ is a symmetric $J \times J$ matrix of nonnegative elements describing the network of connections between blocks that the user wants to take into account. Usually, $c_{jk}=1$ for two connected blocks and 0 otherwise.

-   The $\tau_j$ are called shrinkage parameters ranging from $0$ to $1$ and interpolate smoothly between maximizing the covariance and maximizing the correlation. Setting the $\tau_j$ to 0 will force the block components to unit variance ($\mathrm{var}(\mathbf{X}_j\ensuremath{\mathbf{a}}_j = 1)$), in which case the covariance criterion boils down to the correlation. The correlation criterion is better in explaining the correlated structure across datasets, thus discarding the variance within each individual dataset. Setting $\tau_j$ to 1 will normalize the block weight vectors ($\ensuremath{\mathbf{a}}_j^\top\ensuremath{\mathbf{a}}_j = 1$ ), which applies the covariance criterion. A value between $0$ and $1$ will lead to a compromise between the two first options and correspond to the following constraint $(1-\tau_j)\mathrm{var}(\mathbf{X}_j\ensuremath{\mathbf{a}}_j) + \tau_j \Vert \ensuremath{\mathbf{a}}_j \Vert^2 = 1$ in (\ref{optim_RGCCA}). The choices $\tau_j = 1$, $\tau_j = 0$ and $0<\tau_j<1$ are respectively referred as Modes A, B and Ridge. In the RGCCA package, for each block, the determination of the shrinkage parameter can be made fully automatic by using the analytical formula proposed by [@Schafer2005]. Also, depending on the context, the shrinkage parameters should also be determined based on cross-validation or permutation. We can define the choice of the shrinkage parameters by providing interpretations on the properties of the resulting block components:

    -   $\tau_j=1$ yields the maximization of a covariance-based criterion. It is recommended when the user wants a stable component (large variance) while simultaneously taking into account the correlations between blocks. The user must, however, be aware that variance dominates over correlation.

    -   $\tau_j=0$ yields the maximization of a correlation-based criterion. It is recommended when the user wants to maximize correlations between connected components. This option can yield unstable solutions in case of multi-collinearity and cannot be used when a data block is rank deficient (e.g. $n<p_j$).

    -   $0<\tau_j<1$ is a good compromise between variance and correlation: the block components are simultaneously stable and as well correlated as possible with their connected block components. This setting can be used when the data block is rank deficient.
    
From optimization problem (\ref{optim_RGCCA}), the term "generalized" in the acronym of RGCCA embraces at four notions. The first one relates to the generalization of two-block methods - including Canonical Correlation Analysis [@Hotelling1936] Interbattery Factor Analysis [@Tucker1958] and Redundancy Analysis [@Wollenberg1977] - to three or more sets of variables. The second one relates to the ability of taking into account some hypotheses on between-block connections: the user decides which blocks are connected and which ones are not. The third one relies on the choices of the shrinkage parameters allowing to capture both correlation or covariance-based criteria. The fourth one relates to the function $g$ that enables to consider different functions of the covariance. This generalization is embodied by a triplet of parameters: ($g, \tau_j, \mathbf C$) and by the fact that an arbitrary number of blocks can be handled. This triplet of parameters offers a flexibility to RGCCA
and allows to encompasses a large number of multiblock component methods that were published for fifty years. Table 1 gives the correspondences between the triplet $g, \tau_j, \mathbf C$) and the corresponding methods. For a complete overview see [@Tenenhaus2017].


| **Methods**                                         | $g(x)$ | $\tau_j$                                                                                   | $\ensuremath{\mathbf{C}}$                                                                                                                                     |
|-------------|-------------|----------------|------------------------------|
| **Canonical Correlation Analysis** [@Hotelling1936] | $x$    | $\tau_1 = \tau_2 = 0$                                                                      | $\ensuremath{\mathbf{C}}_1 = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$                                                                                    |
| **Interbattery Factor Analysis** [@Tucker1958]      | $x$    | $\tau_1 = \tau_2 = 1$                                                                      | $\ensuremath{\mathbf{C}}_1$                                                                                                                                   |
| **Redundancy Analysis** [@Wollenberg1977]           | $x$    | $\tau_1 = 1$ and $\tau_2 = 0$                                                              | $\ensuremath{\mathbf{C}}_1$                                                                                                                                   |
| **SUMCOR** [@Horst1961]                             | $x$    | $\tau_j = 0, j=1, \ldots, J$                                                               | $\ensuremath{\mathbf{C}}_2 = \begin{pmatrix} 1 & 1 & \cdots & 1 \\ 1 & 1 & \ddots & \vdots \\ \vdots & \ddots& \ddots & 1\\ 1 & \cdots & 1 & 1 \end{pmatrix}$ |
| **SSQCOR** [@Kettenring1971]                        | $x^2$  | $\tau_j = 0, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_2$                                                                                                                                   |
| **SABSCOR** [@Hanafi2007]                           | $|x|$  | $\tau_j = 0, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_2$                                                                                                                                   |
| **SUMCOV-1** [@VandeGeer1984]                       | $x$    | $\tau_j = 1, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_2$                                                                                                                                   |
| **SSQCOV-1** [@Hanafi2006]                          | $x^2$  | $\tau_j = 1, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_2$                                                                                                                                   |
| **SABSCOV-1** [@Tenenhaus2011 ; @Kramer2007]        | $|x|$  | $\tau_j = 1, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_2$                                                                                                                                   |
| **SUMCOV-2** [@VandeGeer1984]                       | $x$    | $\tau_j = 1, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_3 = \begin{pmatrix} 0 & 1 & \cdots & 1 \\ 1 & 0 & \ddots & \vdots\\ \vdots & \ddots& \ddots& 1\\ 1 & \cdots & 1 & 0 \end{pmatrix}$   |
| **SSQCOV-2** [@Hanafi2006]                          | $x^2$  | $\tau_j = 1, 1 \le j \le J$                                                                | $\ensuremath{\mathbf{C}}_3$                                                                                                                                   |
| **Generalized CCA** [@Carroll1968a]                 | $x^2$  | $\tau_j = 0, 1 \le j \le J+1$                                                              | $\ensuremath{\mathbf{C}}_4 = \begin{pmatrix} 0 & \cdots & 0 & 1 \\ \vdots & \ddots & \vdots & \vdots\\ 0 & \cdots & 0 & 1\\ 1 & \cdots & 1 & 0 \end{pmatrix}$ |
| **Generalized CCA** [@Carroll1968b]                 | $x^2$  | $\tau_j=0, 0 \leq j \leq J_1 = 0 ~\&~\tau_{J+1} = 0$ and $\tau_j = 1, J_1+1 \leq j \leq J$ | $\ensuremath{\mathbf{C}}_4$                                                                                                                                   |
| **Hierarchical PCA** [@Wold1996]                    | $x^4$  | $\tau_j = 1, 1 \le j \le J$ and $\tau_{J+1} = 0$                                           | $\ensuremath{\mathbf{C}}_4$                                                                                                                                   |
| **Multiple Co-Inertia Analysis** [@Chessel1996]     | $x^2$  | $\tau_j = 1, 1 \le j \le J$ and $\tau_{J+1} = 0$                                           | $\ensuremath{\mathbf{C}}_4$                                                                                                                                   |
| **PLS path modeling - mode B** [@Wold1982]          | $|x|$  | $\tau_j = 0, 1 \le j \le J$                                                                | $c_{jk}=1$ for two connected block and $c_{jk} = 0$ otherwise                                                                                                 |
**Table1.** Special cases of RGCCA in a situtation of $J \ge 2$ blocks. When $\tau_{J+1}$ is introduced, it is assumed that $\ensuremath{\mathbf{X}}_1, \ldots, \ensuremath{\mathbf{X}}_J$ are connected to a $(J + 1)$th block defined as the concatenation of the blocks, $\ensuremath{\mathbf{X}}_{J+1} = \bigg[\ensuremath{\mathbf{X}}_1 , \ensuremath{\mathbf{X}}_2, \ldots, \ensuremath{\mathbf{X}}_J \bigg]$ and that $\tau_{J+1}$ corresponds to the shrinkage parameter associated with $\ensuremath{\mathbf{X}}_{J+1}$.

For all the methods reported in Table 1, a single very simple monotonically and globally convergent algorithm is proposed for solving the optimization problem (\ref{optim_RGCCA}) - i.e. the bounded criterion to be maximized increases at each step of the iterative procedure -, which hits at convergence a stationary point of (\ref{optim_RGCCA}). Two numerically equivalent approaches for solving the RGCCA optimization problem are available. A primal formulation described in [@Tenenhaus2017 ; @Tenenhaus2011] requires the handling of matrices of dimension $p_j \times p_j$. A dual formulation described in [@Tenenhaus2015] requires the handling of matrices of dimension $n \times n$ . Therefore, the primal formulation of the RGCCA algorithm will be prefered when $n>p_j$ and the dual form will be used when $n\le p_j$. From these perspectives, RGCCA provide a general framework for exploratory data analysis of multiblock datasets that has immediate practical consequences for a unified statistical analysis and implementation strategy. 


It is possible to obtain more than one block-component per block. Higher stage block components is obtained using a deflation strategy. 
This strategy forces all the block components within a block to be uncorrelated. This deflation procedure can be iterated in a very flexible way. 
It is not necessary to keep all the blocks in the procedure at all stages: the number of components summarizing a block can vary from one block to 
another (see [@Tenenhaus2017] for details).

## Variable selection in RGCCA: Sparse Generalized Canonical Correlation Analysis

The quality and interpretability of the RGCCA block components $\mathbf{y}_j= \mathbf{X}_j \ensuremath{\mathbf{a}}_j,j=1, \ldots,J$ are likely affected by the usefulness and relevance of the variables of each block. Accordingly, it is an important issue to identify within each block a subset of significant variables which are active in the relationships between blocks. SGCCA extends RGCCA to address this issue of variable selection. Specifically, RGCCA with all $\tau_j=1$ equal to 1 is combined with an $\ell_1$-penalty that gives rise to SGCCA [@Tenenhaus2014b]. The SGCCA optimization problem is defined as follows:

```{=tex}
\begin{equation}
\displaystyle \underset{\mathbf{a}_1,\mathbf{a}_2, \ldots,\mathbf{a}_J}{\text{maximize}} \sum_{j, k = 1}^J c_{jk}g(\mathrm{cov}(\mathbf{X}_j\ensuremath{\mathbf{a}}_j, \mathbf{X}_k\ensuremath{\mathbf{a}}_k)) \mathrm{~~s.t.~~} \Vert \mathbf{a}_j \Vert_2 = 1 \text{~and~} \Vert \mathbf{a}_j \Vert_1 \le s_j, j=1,\ldots,J
\label{optim_SGCCA}
\end{equation}
```

where $s_j$ is a user defined positive constant that determines the amount of sparsity for $\ensuremath{\mathbf{a}}_j, j=1, \ldots,J$. The smaller the $s_j$, the larger the degree of sparsity for $\ensuremath{\mathbf{a}}_j$. The sparsity parameter $s_j$ is usually set based on cross-validation procedures. Alternatively, values of $s_j$ can simply be chosen to result in desired amounts of sparsity.


Guidelines describing how to use R/SGCCA  in practice are provided in [@Garali2018].


The function `rgcca()`of the RGCCA package implements a monotonically convergent algorithm 

It is possible to obtain more than one block-component per block. Higher stage block components can be obtained using a deflation strategy. This strategy forces all the block components within a block to be uncorrelated. This deflation procedure can be iterated in a very flexible way. It is not necessary to keep all the blocks in the procedure at all stages: the number of components summarizing a block can vary from one block to another (see [@Tenenhaus2017] for details). The superblock configuration need to be treted

Two numerically equivalent approaches for solving the RGCCA optimization problem are available. A primal formulation described in [@Tenenhaus2017 ; @Tenenhaus2011] requires the handling of matrices of dimension $p_j \times p_j$. A dual formulation described in [@Tenenhaus2015] requires the handling of matrices of dimension $n \times n$ . Therefore, the primal formulation of the RGCCA algorithm will be used when $n>p_j$ and the dual form will be preferred when $n\le p_j$ . The `rgcca()` function of the RGCCA package implements these two formulations and selects automatically the best one. The SGCCA algorithm is similar to the RGCCA algorithm and keeps the same convergence properties. The algorithm associated with the optimization problem (2) is available through the function `rgcca()` with the sgcca option (method="sgcca") in the RGCCA package.


# Practical session

## RGCCA for the Russett dataset.

In this section, we propose to reproduce some of the results presented in [@Tenenhaus2011] for the Russett data. The Russett dataset is available within the RGCCA package. The Russett data set [@Russett1964] are studied in [@Gifi1990]. Russett collected this data to study relationships between Agricultural Inequality, Industrial Development and Political Instability.

```{r}
library(RGCCA)
data(Russett)
head(Russett)
```

The first step of the analysis is to define the blocks. Three blocks of variables have been defined for 47 countries. The variables that compose each block have been defined according to the nature of the variables.

-   The first block $\mathbf{X}_1$ = [GINI, FARM, RENT] is related to "Agricultural Inequality":
    -   GINI = Inequality of land distribution,
    -   FARM = % farmers that own half of the land (\> 50),
    -   RENT = % farmers that rent all their land.
-   The second block $\mathbf{X}_2$ = [GNPR, LABO] describes "Industrial Development":
    -   GNPR = Gross national product per capita (\$1955),
    -   LABO = % of labor force employed in agriculture.
-   The third one $\mathbf{X}_3$ = [INST, ECKS, DEAT] measures "Political Instability":
    -   INST = Instability of executive (45-61),
    -   ECKS = Number of violent internal war incidents (46-61),
    -   DEAT = Number of people killed as a result of civic group violence (50-62).
    -   An additional variable DEMO describes the political regime: stable democracy, unstable democracy or dictatorship. The dummy variable "unstable democracy" has been left out because of redundancy.

The different blocks of variables $\ensuremath{\mathbf{X}}_1, \ldots, \ensuremath{\mathbf{X}}_J$ are arranged in the list format.

```{r}
X_agric = Russett[,c("gini","farm","rent")]
X_ind = Russett[,c("gnpr","labo")]
X_polit = Russett[ , c("inst", "ecks",  "death",
                       "demostab", "dictator")]
A = list(Agric = X_agric, Ind = X_ind, Polit = X_polit)

sapply(A, head)


lab = factor(apply(Russett[, 9:11], 1, which.max),
             labels = c("demost", 
                        "demoinst", 
                        "dict"))
```

**Preprocessing** In order to ensure comparability between variables standardization is applied (zero mean and unit variance). Such a preprocessing is reached by setting the `scale` argument to `TRUE` (default value) in the `rgcca()` function.

To make blocks comparable, a possible strategy is to standardize the variables and then to divide each block by the square root of its number of variables [@Westerhuis1998]. This two-step procedure leads to $\mathrm{tr}(\ensuremath{\mathbf{X}}_j^\top \ensuremath{\mathbf{X}}_j )=n$ for each block (i.e. the sum of the eigenvalues of the covariance matrix of $\ensuremath{\mathbf{X}}_j$ is equal to $1$ whatever the block). Such a preprocessing is reached by setting the `scale_block` argument to `TRUE` or `inertia` (default value) in the `rgcca()` function. If  `scale_block = "lambda1"`, each block is divided by the square root of the highest eigenvalue of its empirical covariance matrix.  If standardization is applied (scale = TRUE), the block scaling is applied on the result of the standardization.

**Definition of the design matrix** $\mathbf{C}$. From Russett's hypotheses, it is difficult for a country to escape dictatorship when its agricultural inequality is above-average and its industrial development below-average. These hypotheses on the relationships between blocks are depicted in Figure \ref{fig:C}.

```{=tex}
\begin{figure}[!!!h]
\centering
\begin{tikzpicture}
\tikzstyle{every node}=[draw,shape=circle,auto,node distance=3.5cm];
\node (Polit) {Polit};
\node (Agric) [above left of=Polit] {Agric};
\node (Indust) [below left of=Polit] {Indust};
\draw (Agric) -- (Polit)
(Indust) -- (Polit);
\end{tikzpicture}
\caption{between-block connection.}
\label{fig:C}
\end{figure}
```

and encoded through the design matrix $\mathbf{C}$; usually $c_{jk} = 1$ for two connected blocks and $0$ otherwise. Therefore, we have decided to connect Agricultural Inequality to Political Instability ($c_{13} = 1$), Industrial Development to Political Instability ($c_{23} = 1$) and to not connect Agricultural Inequality to Industrial Development ($c_{12} = 0$). The resulting design matrix $\ensuremath{\mathbf{C}}$ is:

```{r}
#Define the design matrix C.
C = matrix(c(0, 0, 1,
             0, 0, 1,
             1, 1, 0), 3, 3)

C
```

RGCCA using the pre-defined design matrix $\ensuremath{\mathbf{C}}$, 
the factorial scheme ($g(x) = x^2$), $\tau = 1$ for all blocks (full covariance criterion) and the number of components equal to $2$ for all blocks is obtained by specifying appropriately the `connection`, `scheme`, `tau` and `ncomp` arguments of the `rgcca()` function. The `verbose` argument (default value = `TRUE`) indicates that the progress will be reported while computing and that a plot representing the convergence of the algorithm will be returned.

```{r}
fit = rgcca(blocks = A, connection = C, 
            tau = rep(1, 3), ncomp = 2, 
            scheme = "factorial",  
            scale = TRUE, scale_block = FALSE,
            verbose = FALSE)
```

the print() function allows summarizing the RGCCA analysis

```{r}
print(fit)
```

The block-weight vectors solution of the optimization problem (\ref{optim_RGCCA}) are available as output of the `rgcca()` function in `fit$a` and correspond exactly to the weight vectors reported in [@Tenenhaus2011, see Figure 5]. It is possible to display specific block-weight vector(s) (`type = "weight"`) block-loadings vector(s) (`type = "loadings"`) using the generic `plot()` function and specifying the arguments `block` and `component` accordingly. 

```{r}
plot(fit, type = "weight", block = 1:3, comp = 1, cex = .7)
```

**Assessment of the reliability of parameter estimates.** It is possible to use a bootstrap resampling method to assess the reliability of parameter estimates (block-weight/loading vectors) obtained using RGCCA. $B$ bootstrap samples of the same size as the original data is repeatedly sampled with replacement from the original data. RGCCA is then applied to each bootstrap sample to obtain the RGCCA estimates. We calculate the standard deviation of the estimates across the bootstrap samples, from which we derived, bootstrap confidence intervals, t-ratio (defined as the ratio of the parameter estimate to its bootstrap estimate of the standard deviation) and p-value (the p-value is computed by assuming that the ratio of the parameter estimate to its standard deviation follows the standardized normal distribution) to indicate how reliably parameters were estimated. Since several p-values are constructed simultaneously, FDR correction can be applied for controlling the False Discovery Rate. This function is available using the `bootstrap()` function of the RGCCA package.

```{r}
boot.out = rgcca_bootstrap(fit, n_boot = 500, n_cores = 1)
```

The bootstrap results are detailed using the `print()` function.

```{r}
print(boot.out, block = 1:3, ncomp = 2)
```

and displayed using the `plot()`function.

```{r}
plot(boot.out, type = "weight", 
     block = 1:3, comp = 1, 
     display_order = FALSE, cex = .7)
```

At last, as a component-based method, RGCCA provides block components as output of the `rgcca()` function in `fit$Y` a graphical representations, including factor plot, correlation circle. This graphical displays allows visualizing the sources of variability within blocks, the relationships between variables within and between blocks and the amount of correlation between blocks. The graphical display of the countries obtained by crossing $\ensuremath{\mathbf{X}}_1 \ensuremath{\mathbf{a}}_1$ = Agricultural Inequality and $\ensuremath{\mathbf{X}}_2 \ensuremath{\mathbf{a}}_2$ = Industrial Development and marked with their political regime in 1960 is shown in below.

```{r, eval=TRUE, fig.align='center', fig.cap = 'graphical display of the countries obtained by crossing y11 and y21 and labeled according to their political regime',fig.height = 6, fig.width = 8}
plot(fit, type = "sample",
     block = 1:2, comp = 1,
     resp = lab, repel = TRUE, cex = .7)
```

Countries aggregate together when they share similarities. It may be noted that the lower ight quadrant concentrates on dictatorships. It is difficult for a country to escape dictatorship when its industrial development is below-average and its agricultural inequality is above average. It is worth pointing out that some unstable democracies located in this quadrant (or close to it) became dictatorships for a period of time after 1960: Greece (1967-1974), Brazil (1964-1985), Chili (1973-1990), and Argentina (1966-1973). The Average Variance Explained (AVE) defined below is also reported in the axis of the Figure.  The AVE of block $\ensuremath{\mathbf{X}}_j$ for a specific block component $\ensuremath{\mathbf{y}}_j$ is defined as:

```{=tex}
\begin{equation}
\mathrm{AVE}(\ensuremath{\mathbf{X}}_j)=  1/p_j \sum_{h=1}^{p_j} cor^2( \ensuremath{\mathbf{x}}_{jh},\ensuremath{\mathbf{y}}_j)
\end{equation}
```

AVE($\ensuremath{\mathbf{X}}_j$) varies between 0 and 1 and reflects the proportion of variance captured by $\ensuremath{\mathbf{y}}_j$.

Additional indicators of model quality are proposed:

-   For all blocks:

```{=tex}
\begin{equation}
\displaystyle \mathrm{AVE(outer model)} = \left( 1/\sum_j p_j \right) \sum_j p_j \mathrm{AVE}(\ensuremath{\mathbf{X}}_j)
\end{equation}
```

-   For the inner model:

```{=tex}
\begin{equation}
\displaystyle \mathrm{AVE(inner model)} = \left( 1/\sum_{j<k} c_{jk} \right) \sum_{j<k} c_{jk} \mathrm{cor}^2(\ensuremath{\mathbf{y}}_j , \ensuremath{\mathbf{y}}_k)
\end{equation}
```

These indicators of model quality are also available as output of the `rgcca()` function in `fit$AVE`. These AVEs can be visualized using the generic `plot()` function.

```{r, eval = FALSE, fig.align='center', fig.cap = 'Average variance explained of the various blocks', fig.height = 5, fig.width = 8}
plot(fit, type = "ave")
```

## Choice of the shrinkage parameter $\tau$

As described in this section, three fully automatic strategies are proposed to select the optimal shrinkage parameters:

**Choice of the shrinkage parameter using the Schafer and Strimmer analytical formula [@Schafer2005]** For each block $j$, an "optimal" shrinkage parameter $\tau_j$ can be obtained from the Schafer and Strimmer analytical formula [@Schafer2005] by setting the `tau` argument of the  the `rgcca()` function to `"optimal"`.

```{r}
fit = rgcca(blocks = A, connection=C, response=3,
            tau = "optimal", scheme = "factorial", 
            scale = TRUE, scale_block = TRUE, 
            verbose = TRUE)
```

The optimal shrinkage parameters are given by:

```{r}
fit$call$tau
```

This automatic estimation of the shrinkage parameters allows one to come closer to the correlation criterion, even in the case of high multicollinearity or when the number of individuals is smaller than the number of variables.

As previoulsy, all the output of this model can visualized/bootstraped using the plot() and bootstrap() functions.

**Choice of the shrinkage parameter by permutation strategy.** A permutation based strategy very similar to the one proposed in [@Witten2009a] has been also integrated within the RGCCA package through the `rgcca_permutation()` function. This function is used to select automatically the regularization parameters for R/SGCCA.

For each set of regularization parameters (generally this will be a $J$-dimensional vector), repeat the following `n_perm` times, for (`n_perm` large):

```{=tex}
\begin{enumerate}
\item [\label{p1}] The samples in $\mathbf X_1, \ldots, \mathbf X_J$ are
randomly permuted to obtained data sets $\mathbf X_1^*, \ldots, \mathbf X_J^*$.
%
\item [\label{p2}] S/RGCCA is run on the permuted data set
$\mathbf X_1^*, \ldots, \mathbf X_J^*$ to get block weight vectors
$\mathbf w_1^*, \ldots, \mathbf w_J^*$.
%
\item [\label{p3}]  Record $t^* = \displaystyle \sum_{j,k} c_{jk} g(\text{cov}(\mathbf X_j^*\mathbf w_j^*, \mathbf X_k^*\mathbf w_k^*))$.
%
\item [\label{p4}]  S/RGCCA is run on the original data
$\mathbf X_1, \ldots, \mathbf X_J$ to obtain the block weight vectors
$\mathbf w_1, \ldots, \mathbf w_J$.
%
\item [\label{p5}]  Record $t = \displaystyle \sum_{j,k} c_{jk} g(\text{cov}(\mathbf X_j\mathbf w_j, \mathbf X_k\mathbf w_k))$.
%
\item [\label{p6}]  The resulting p-value is given by the fraction of permuted
$t*$ that exceed the real $t$t obtained from the real data.
\end{enumerate}
```

Then choose the set of tuning parameters that gives the smallest value in step (\ref{p6}).

This procedure is available though the `rgcca_permutation()` function.

```{r}
set.seed(123)
perm_out = rgcca_permutation(blocks = A, connection=C, 
                             par_type = "tau", 
                             par_length = 10,
                             n_cores = 1,
                             n_perms = 50)
```

By default, the `rgcca_permutation()` function takes, for each block, 10 sets of tuning parameters between min values (0 for RGCCA and $1/sqrt(ncol)$ for SGCCA) and 1.

Results of the permutation procedure are summarized using the generic `print()` function

```{r}
print(perm_out)
```

and displayed using the `plot()` function.

```{r}
plot(perm_out, cex = .7)
```

The fitted permutation object, `perm_out`, can be provided as output of `rgcca()` and visualized/bootstrapped in a very straightforward way as previously.

```{r}
fit = rgcca(perm_out)
```

Of course, it is  possible to define explicitly the combination of regularization parameters to be tested. In that case a matrix of dimension $K \times J$ is required. Each row of this matrix corresponds to one set of tuning parameters.

```{r}
fit.perm = rgcca_permutation(A, connection = C,
                             par_type = "tau",
                             par_value = rbind(rep(1, 3),
                                               seq(0, 1, l=3),
                                               rep(0, 3),
                                               sapply(A, RGCCA:::tau.estimate)),
                             n_cores = 1, n_perms = 5)
```

Alternatively a numeric vector of length $J$ indicating the range of values to be tested: from the minimum values (0 for RGCCA and $1/sqrt(ncol)$ for SGCCA) to the maximum values specified by the user with `par_value`.

```{r}
fit.perm = rgcca_permutation(A, connection = C,
                             par_type = "tau",
                             par_value = seq(0, 1, l=3),
                             n_cores = 1, n_perms = 5)
```

**Choice of the shrinkage parameter by cross-validation strategy.** 
The optimal tuning parameters can be determined fully automatically  by cross-validating different indicators of quality (e.g. accuracy, F1 score, ...). This strategy has been also integrated within the RGCCA package through the `rgcca_cv()`. This function is applied for predicting the qualitative variable political regime form Agriculture inequality and Industrial development  .

```{r}
blocks <- list(agriculture = Russett[, seq(3)],
               industry = Russett[, 4:5],
               lab = factor(apply(Russett[, 9:11], 1, which.max),
                            labels = c("Stable democracy", 
                                       "Unstable democracy",
                                       "Dictatorship"))
               )

cv_out = rgcca_cv(blocks = blocks, response = 3, 
                  par_type = "tau", 
                  prediction_model = "lda", 
                  n_run = 10, k = 3,
                  validation = "kfold", 
                  metric = "Accuracy",
                  ncomp = 1)

```

Results of the cross validation procedure are summarized using the generic `print()` function

```{r}
print(cv_out)
```

and displayed using the `plot()` function.

```{r}
plot(cv_out, cex = .7)
```

The fitted cval object, `cv_out`, can be provided as output of `rgcca()` and the cross-validated model can be visualized/bootstrapped in a very straightforward way as previously.

```{r}
fit = rgcca(cv_out)
```

If `par_type = sparsity`, the `rgcca_cv()` function switches automatically to sparse analysis. The same rational is used for the other arguments of the function.

# Conclusion

This package gathers 60 years of multiblock component methods and offers a unified implementation strategy for these methods. This release of the RGCCA package includes:

-   K-fold cross-validation and permutation based strategies for optimal choice of the shrinkage parameters/level of sparsity.

-   a bootstrap resampling procedure for assessing the reliability of the parameters estimates of S/RGCCA.

-   Dedicated functions for graphical representations of the ouptut of RGCCA (sample plot, correlation circle, etc...).

-   multiblock data faces two types of missing data structure: (i) if an observation $i$ has missing values on a whole block j and (ii) if an observation i has some missing values on a block j (but not all). For these two situations, it is possible to exploit the algorithmic solution proposed for PLS path modeling to deal with missing data (see [@Tenenhaus2005], page 171).

At last, RGCCA for multigroup data [@Tenenhaus2014b] and for RGCCA for multiway data [@Gloaguen2020] has been proposed but not yet integrated in the RGGCA package. In addition, global RGCCA has been recently developed and enables extracting simultaneously several components per block (no deflation procedure required). Work in progress includes the integration of this novel procedures in the next release of the package.

# References
